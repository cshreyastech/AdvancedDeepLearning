{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# based on https://github.com/experiencor/keras-yolo3\n",
    "import struct\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_block(inp, convs, skip=True):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
    "        x = Conv2D(conv['filter'],\n",
    "                   conv['kernel'],\n",
    "                   strides=conv['stride'],\n",
    "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "                   name='conv_' + str(conv['layer_idx']),\n",
    "                   use_bias=False if conv['bnorm'] else True)(x)\n",
    "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "    return add([skip_connection, x]) if skip else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yolov3_model():\n",
    "    input_image = Input(shape=(None, None, 3))\n",
    "    # Layer  0 => 4\n",
    "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "    # Layer  5 => 8\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "    # Layer  9 => 11\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "    # Layer 12 => 15\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "    # Layer 16 => 36\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "    skip_36 = x\n",
    "    # Layer 37 => 40\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "    # Layer 41 => 61\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "    skip_61 = x\n",
    "    # Layer 62 => 65\n",
    "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "    # Layer 66 => 74\n",
    "    for i in range(3):\n",
    "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "    # Layer 75 => 79\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "    # Layer 80 => 82\n",
    "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
    "    # Layer 83 => 86\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_61])\n",
    "    # Layer 87 => 91\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "    # Layer 92 => 94\n",
    "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
    "    # Layer 95 => 98\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_36])\n",
    "    # Layer 99 => 106\n",
    "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
    "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major, = struct.unpack('i', w_f.read(4))\n",
    "            minor, = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                w_f.read(4)\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            binary = w_f.read()\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "\n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "    def load_weights(self, model):\n",
    "        for i in range(106):\n",
    "            try:\n",
    "                conv_layer = model.get_layer('conv_' + str(i))\n",
    "                print(\"loading weights of convolution #\" + str(i))\n",
    "                if i not in [81, 93, 105]:\n",
    "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
    "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "                    beta  = self.read_bytes(size) # bias\n",
    "                    gamma = self.read_bytes(size) # scale\n",
    "                    mean  = self.read_bytes(size) # mean\n",
    "                    var   = self.read_bytes(size) # variance\n",
    "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel, bias])\n",
    "                else:\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel])\n",
    "            except Exception as e:\n",
    "                print(\"no convolution #\" + str(i))\n",
    "                print('Failed to load weight: '+ str(e))\n",
    "                print('--------------------------------------')\n",
    "                break\n",
    "\n",
    "    def reset(self):\n",
    "        self.offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights of convolution #0\n",
      "no convolution #0\n",
      "Failed to load weight: OOM when allocating tensor of shape [] and type float\n",
      "\t [[node conv_9_6/random_uniform/min (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3536) ]]\n",
      "\n",
      "Caused by op 'conv_9_6/random_uniform/min', defined at:\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-6e3b97f26d38>\", line 2, in <module>\n",
      "    model = make_yolov3_model()\n",
      "  File \"<ipython-input-3-be0a81b15e58>\", line 14, in make_yolov3_model\n",
      "    {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
      "  File \"<ipython-input-2-9796d1dbb039>\", line 14, in _conv_block\n",
      "    use_bias=False if conv['bnorm'] else True)(x)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 569, in __call__\n",
      "    self.build(input_shapes[0])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\", line 134, in build\n",
      "    constraint=self.kernel_constraint)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 391, in add_weight\n",
      "    weight = K.variable(initializer(shape), dtype=dtype, name=name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/initializers.py\", line 208, in __call__\n",
      "    dtype=dtype, seed=self.seed)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 3536, in random_uniform\n",
      "    dtype=dtype, seed=seed)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py\", line 240, in random_uniform\n",
      "    minval = ops.convert_to_tensor(minval, dtype=dtype, name=\"min\")\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1039, in convert_to_tensor\n",
      "    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1097, in convert_to_tensor_v2\n",
      "    as_ref=False)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1175, in internal_convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\", line 304, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\", line 245, in constant\n",
      "    allow_broadcast=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\", line 289, in _constant_impl\n",
      "    name=name).outputs[0]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "ResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [] and type float\n",
      "\t [[node conv_9_6/random_uniform/min (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3536) ]]\n",
      "\n",
      "--------------------------------------\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value conv_0_6/kernel\n\t [[node conv_0_6/kernel (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321) ]]\n\t [[node conv_0_6/kernel (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321) ]]\n\nCaused by op 'conv_0_6/kernel', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-6e3b97f26d38>\", line 2, in <module>\n    model = make_yolov3_model()\n  File \"<ipython-input-3-be0a81b15e58>\", line 7, in make_yolov3_model\n    {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n  File \"<ipython-input-2-9796d1dbb039>\", line 14, in _conv_block\n    use_bias=False if conv['bnorm'] else True)(x)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 569, in __call__\n    self.build(input_shapes[0])\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\", line 134, in build\n    constraint=self.kernel_constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 391, in add_weight\n    weight = K.variable(initializer(shape), dtype=dtype, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 321, in variable\n    v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1531, in _init_from_args\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\", line 79, in variable_op_v2\n    shared_name=shared_name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 1425, in variable_v2\n    shared_name=shared_name, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv_0_6/kernel\n\t [[node conv_0_6/kernel (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321) ]]\n\t [[node conv_0_6/kernel (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv_0_6/kernel\n\t [[{{node conv_0_6/kernel}}]]\n\t [[{{node conv_0_6/kernel}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6e3b97f26d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mweight_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# save the model to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/cstx2/RawFileRepo/yolo3/model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   2504\u001b[0m         \"\"\"\n\u001b[1;32m   2505\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2506\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mmodel_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minclude_optimizer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2800\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2801\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2802\u001b[0;31m         \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2803\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2804\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2136\u001b[0m     \"\"\"\n\u001b[1;32m   2137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv_0_6/kernel\n\t [[node conv_0_6/kernel (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321) ]]\n\t [[node conv_0_6/kernel (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321) ]]\n\nCaused by op 'conv_0_6/kernel', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-6e3b97f26d38>\", line 2, in <module>\n    model = make_yolov3_model()\n  File \"<ipython-input-3-be0a81b15e58>\", line 7, in make_yolov3_model\n    {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n  File \"<ipython-input-2-9796d1dbb039>\", line 14, in _conv_block\n    use_bias=False if conv['bnorm'] else True)(x)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 569, in __call__\n    self.build(input_shapes[0])\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\", line 134, in build\n    constraint=self.kernel_constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 391, in add_weight\n    weight = K.variable(initializer(shape), dtype=dtype, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 321, in variable\n    v = tf.Variable(value, dtype=_convert_string_dtype(dtype), name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1531, in _init_from_args\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\", line 79, in variable_op_v2\n    shared_name=shared_name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 1425, in variable_v2\n    shared_name=shared_name, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv_0_6/kernel\n\t [[node conv_0_6/kernel (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321) ]]\n\t [[node conv_0_6/kernel (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321) ]]\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = make_yolov3_model()\n",
    "# load the model weights\n",
    "weight_reader = WeightReader('/home/cstx2/RawFileRepo/yolo3/yolov3.weights')\n",
    "# set the model weights into the model\n",
    "weight_reader.load_weights(model)\n",
    "# save the model to file\n",
    "model.save('/home/cstx2/RawFileRepo/yolo3/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yolov3 model and perform object detection\n",
    "# based on https://github.com/experiencor/keras-yolo3\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "    boxes = []\n",
    "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "    for i in range(grid_h*grid_w):\n",
    "        row = i / grid_w\n",
    "        col = i % grid_w\n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            if(objectness.all() <= obj_thresh): continue\n",
    "            # first 4 elements are x, y, w, and h\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "            x = (col + x) / grid_w # center position, unit: image width\n",
    "            y = (row + y) / grid_h # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "            # last elements are class probabilities\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "            boxes.append(box)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    new_w, new_h = net_w, net_h\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    intersect = intersect_w * intersect_h\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    return float(intersect) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "    # load the image to get its shape\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "    # load the image with the required size\n",
    "    image = load_img(filename, target_size=shape)\n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    # add a dimension so that we have one sample\n",
    "    image = expand_dims(image, 0)\n",
    "    return image, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    # enumerate all boxes\n",
    "    for box in boxes:\n",
    "        # enumerate all possible labels\n",
    "        for i in range(len(labels)):\n",
    "            # check if the threshold for this label is high enough\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i]*100)\n",
    "                # don't break, many labels may trigger for one box\n",
    "    return v_boxes, v_labels, v_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw all results\n",
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "    # load the image\n",
    "    data = pyplot.imread(filename)\n",
    "    # plot the image\n",
    "    pyplot.imshow(data)\n",
    "    # get the context for drawing boxes\n",
    "    ax = pyplot.gca()\n",
    "    # plot each box\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        # create the shape\n",
    "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "        # draw text and score in top left corner\n",
    "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "        pyplot.text(x1, y1, label, color='white')\n",
    "    # show the plot\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yolov3 model\n",
    "model = load_model('/home/cstx2/RawFileRepo/yolo3/model.h5')\n",
    "# define the expected input shape for the model\n",
    "input_w, input_h = 416, 416\n",
    "# define our new photo\n",
    "photo_filename = '/home/cstx2/RawFileRepo/yolo3/zebra.jpg'\n",
    "# load and prepare image\n",
    "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
    "# make prediction\n",
    "yhat = model.predict(image)\n",
    "# summarize the shape of the list of arrays\n",
    "print([a.shape for a in yhat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the anchors\n",
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "# define the probability threshold for detected objects\n",
    "class_threshold = 0.6\n",
    "boxes = list()\n",
    "for i in range(len(yhat)):\n",
    "    # decode the output of the network\n",
    "    boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
    "# correct the sizes of the bounding boxes for the shape of the image\n",
    "correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "# suppress non-maximal boxes\n",
    "do_nms(boxes, 0.5)\n",
    "# define the labels\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "    \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "    \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "    \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "    \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "    \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "    \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the details of the detected objects\n",
    "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "# summarize what we found\n",
    "for i in range(len(v_boxes)):\n",
    "    print(v_labels[i], v_scores[i])\n",
    "# draw what we found\n",
    "draw_boxes(photo_filename, v_boxes, v_labels, v_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
